{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27820656-b3bd-4151-a1cd-c9f00098e20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "sys.path.append('../../../')\n",
    "from agora.DAG.algorithm.gnnDeepRL.agent import Agent\n",
    "from cogito.machine import MachineConfig\n",
    "from agora.DAG.utils.csv_reader import CSVReader\n",
    "from agora.auxiliary.tools import average_completion, average_slowdown\n",
    "from agora.DAG.adapter.episode import Episode\n",
    "from agora.DAG.algorithm.gnnDeepRL.DRL import RLAlgorithm\n",
    "from agora.DAG.algorithm.gnnDeepRL.reward_giver import EnergyOptimisationRewardGiverV2\n",
    "from agora.DAG.utils.feature_functions import *\n",
    "from agora.DAG.algorithm.gnnDeepRL.utils import ExperienceBuffer\n",
    "# Import the CloudResourceGNN and train_gnn_ac functions\n",
    "from agora.DAG.algorithm.gnnDeepRL.brain import CloudResourceGNN, train_gnn_ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e71730-84cf-492d-b2fb-0f6f727d2937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataframe:  98434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AH274303\\Documents\\GitHub\\Cloud-GradientAccu\\agora\\DAG\\launch_scripts\\../../..\\agora\\DAG\\utils\\csv_reader.py:18: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  df.instances_num = df.inst_num.astype(dtype=int)\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(41)\n",
    "\n",
    "# ************************ Parameters Setting Start ************************\n",
    "machines_number = 5\n",
    "jobs_len = 10\n",
    "n_iter = 30\n",
    "jobs_csv = '../jobs_files/batch_task.csv'\n",
    "\n",
    "reward_giver = EnergyOptimisationRewardGiverV2()\n",
    "\n",
    "name = f'GNN-{machines_number}'\n",
    "model_dir = f'./agents/{name}'\n",
    "summary_path = f'./Tensorboard/{name}'\n",
    "\n",
    "# ************************ Parameters Setting End ************************\n",
    "\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "csv_reader = CSVReader(jobs_csv)\n",
    "machine_configs = [\n",
    "                   MachineConfig(240, 1, 1, \"ThinkSystem-SR850-V3\",1900), MachineConfig(8, 1, 1, \"HPProLiant-ML30-Gen11\",3200),\n",
    "                   MachineConfig(80, 1, 1, \"FALINUX-AnyStor-700EC-NM\",3000),MachineConfig(64, 1, 1, \"Dell-PowerEdgeHS5610\",2100), MachineConfig(120, 1, 1, \"FusionServer-1288H-V7\",1900)]\n",
    "from agora.DAG.algorithm.gnnDeepRL.utils import *\n",
    "\n",
    "# Initialize GNN model\n",
    "node_feature_dim = 5  # Adjust based on your DAG node features\n",
    "resource_feature_dim = 35  # Adjust based on your resource features\n",
    "hidden_dim = 64\n",
    "action_dim = len(machine_configs)  # Number of possible actions (machines to allocate)\n",
    "experience_buffer=ExperienceBuffer(100000)\n",
    "agent = Agent(\"gnn\",0.95, reward_to_go=True, nn_baseline=True, normalize_advantages=True,experience_buffer=experience_buffer)\n",
    "jobs_len=5\n",
    "\n",
    "epsilon = 1.0  # Start with full exploration\n",
    "epsilon_min = 0.01  # Minimum exploration\n",
    "epsilon_decay = 0.995  # Epsilon decay rate per step\n",
    "# Main training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c9251e3-b2f5-43c9-abde-6d1e43fac9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.4.1+cu124\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: C:\\Users\\AH274303\\AppData\\Local\\anaconda3\\envs\\CloudEnvironement\\Lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: torchaudio, torchvision\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bf112e4-4fb6-4b34-9834-cdcc9f77b88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "print(\"PyTorch imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e06fb7e-c2e8-4ae8-9e0e-2759ea46f493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of job_configs is  5\n",
      "Jobs number:  5\n",
      "Tasks number: 17\n",
      "Task instances number mean:  204.1764705882353\n",
      "Task instances number std 744.2816699020938\n",
      "Task instances cpu mean:  96.08182080092192\n",
      "Task instances cpu std:  13.43714373361451\n",
      "Task instances memory mean:  0.37806107749927975\n",
      "Task instances memory std:  0.04604136482569786\n",
      "Task instances duration mean:  124.30452319216364\n",
      "Task instances duration std:  40.37536751800922\n",
      "********** Iteration 0 ************\n",
      "********** Episode 0 ************\n",
      "Epsilon min:  0.01451687645335\r"
     ]
    }
   ],
   "source": [
    "\n",
    "for job_chunk in range(0, 15):\n",
    "    jobs_configs = csv_reader.generate(jobs_len * job_chunk, jobs_len)\n",
    "    algorithm = RLAlgorithm(agent, reward_giver, features_normalize_func=features_normalize_func,\n",
    "                            features_extract_func=features_extract_func, epsilon=epsilon, epsilon_min=epsilon_min,\n",
    "                            epsilon_decay=epsilon_decay)\n",
    "\n",
    "    for itr in range(n_iter):\n",
    "        print(f\"********** Iteration {itr} ************\")\n",
    "        trajectories = []\n",
    "        makespans = []\n",
    "        average_completions = []\n",
    "        average_slowdowns = []\n",
    "\n",
    "        tic = time.time()\n",
    "        # Collect trajectories\n",
    "        for e in range(10):\n",
    "            print(f\"********** Episode {e} ************\")\n",
    "\n",
    "            episode = Episode(machine_configs, jobs_configs, algorithm, None)\n",
    "            algorithm.reward_giver.attach(episode.simulation)\n",
    "            episode.run()\n",
    "            trajectories.append(episode.simulation.scheduler.algorithm.current_trajectory)\n",
    "            makespans.append(episode.simulation.env.now)\n",
    "            average_completions.append(average_completion(episode))\n",
    "            average_slowdowns.append(average_slowdown(episode))\n",
    "            embeddings_log = algorithm.get_embeddings_log()\n",
    "\n",
    "            all_embeddings = np.concatenate(embeddings_log, axis=0)\n",
    "\n",
    "            # Create directory structure\n",
    "            dir_path = f'job_chunk_{job_chunk}/iteration_{itr}'\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            \n",
    "            # Save embeddings to a file\n",
    "            file_path = os.path.join(dir_path, f'embeddings_episode_{e}.npy')\n",
    "            print(f'file_path {file_path}')\n",
    "            np.save(file_path, all_embeddings)\n",
    "\n",
    "        # Extract states, actions, returns, and advantages from trajectories\n",
    "        all_observations = []\n",
    "        all_actions = []\n",
    "        all_rewards = []\n",
    "        all_next_observations = []\n",
    "\n",
    "        for trajectory in trajectories:\n",
    "            observations = []\n",
    "            actions = []\n",
    "            rewards = []\n",
    "            next_observations = []\n",
    "\n",
    "            for i, node in enumerate(trajectory):\n",
    "                observations.append(node.observation)\n",
    "                actions.append(node.action)\n",
    "                rewards.append(node.reward)\n",
    "\n",
    "                # Add next observation\n",
    "                if i < len(trajectory) - 1:\n",
    "                    next_observations.append(trajectory[i + 1].observation)\n",
    "                else:\n",
    "                    # For the last step, use the same observation as next_observation\n",
    "                    # or a terminal state representation if available\n",
    "                    next_observations.append(node.observation)\n",
    "\n",
    "            all_observations.append(observations)\n",
    "            all_actions.append(actions)\n",
    "            all_rewards.append(rewards)\n",
    "            all_next_observations.append(next_observations)\n",
    "\n",
    "        # Assuming all_observations, all_actions, all_rewards, and all_advantages are lists of lists\n",
    "        for observations, actions, rewards, next_observations in zip(all_observations, all_actions,\n",
    "                                                                     all_rewards,\n",
    "                                                                     all_next_observations):\n",
    "            for i, (obs, act, rew, next_obs) in enumerate(\n",
    "                    zip(observations, actions, rewards, next_observations)):\n",
    "                done = 1 if i == len(observations) - 1 else 0  # Assume last step in trajectory is done\n",
    "                experience = (obs, act, rew, next_obs, done)\n",
    "                agent.experience_buffer.add(experience)\n",
    "\n",
    "        update_parameters(agent)\n",
    "        toc = time.time()\n",
    "        print(f\"Iteration {itr}, Time: {(toc - tic) / 12:.2f}\")\n",
    "        print(f\"Average Makespan: {np.mean(makespans):.2f}, \"\n",
    "              f\"Avg Completion: {np.mean(average_completions):.2f}, \"\n",
    "              f\"Avg Slowdown: {np.mean(average_slowdowns):.2f}\")\n",
    "\n",
    "        # Save the model periodically\n",
    "        if (itr + 1) % 10 == 0:\n",
    "            torch.save(agent.actor.state_dict(), f'{model_dir}/actor_model_iter_{itr + 1}.pth')\n",
    "            torch.save(agent.critic.state_dict(), f'{model_dir}/critic_model_iter_{itr + 1}.pth')\n",
    "\n",
    "# Save the final trained model\n",
    "torch.save(agent.actor.sta-te_dict(), f'{model_dir}/actor_model_final.pth')\n",
    "torch.save(agent.critic.state_dict(), f'{model_dir}/critic_model_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38824c2f-ab27-4704-be14-700f1378ceca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9183bc9-9823-4680-85fd-31cb629e0748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudEnv",
   "language": "python",
   "name": "cloudenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
